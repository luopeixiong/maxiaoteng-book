# Aspex数据存储梳理

[TOC]

## 数据归档的建议

Aspex mysql数据库监控策略

1. 归档历史数据
    1. 数据导出
        1. 归档数据可以是csv的格式, 编码这些配置和数据传输程序的一致就可以
        2. 数据应该带id(mysql自增)归档
        3. 对数据条数大实际占用空间不高的表, 到时可直接恢复, 数据量较大的要考虑空间占用, 可以考虑恢复到临时mysql中
        4. 需要考虑整表重传和数据删改的情况, 这种情况要删除历史数据重新归档
    2. 归档顺序
        1. 针对原始表(没有删除归档过数据的表), 可以设置归档策略自动处理
        2. 针对之前已经归档过的表, 因为不带id, 需要等数据库占用降到安全以内, 把这些归档的数据恢复后再做归档
    3. 测试
        1. 先通过单张表的测试, 确认效果满足后再推行
        2. 恢复数据的完整性(条数检查, 分隔符处理, 具体字段的编码问题(比如韩文/日文))
    4. 归档范围
        1. 因为information_schema.tables信息更新延后, 可以设置阈值, 比如行数超过1000w行, 同时占用空间50G以上
        2. 归档日志可以先定六个月之前的
        3. 刚开始可以把条件设大一些, 确保归档的一定是对清理空间最有效的
        4. 除了上次客户提到的luckin的几张表之外, 其他表可以一视同仁
2. 容量尽量降低到60%左右, 确保超过80%的报警能够获取(优先考虑slack通知, 接受人至少包括: dongxu/xiaoteng/Jane), 确保足够时间处理
3. 尽可能降低日志占用, 考虑自动清理

## 解决方案分析

### 0. 现状说明

1. 项目有40个左右, 开始时间: 2019年5月
2. 爬虫在ucloud服务器, 写入ucloud mysql数据库
3. 数据传输程序, 每日凌晨扫描, 增量数据导成csv上传至s3, 客户从s3导入到redshift
4. 视情况, 如果有历史数据调整, 可能需要整表传输
5. 为了解决容量问题, 对于每月一次且数据量较大的项目, 每个月建一个表, 传输结束后直接删除

### 1. 面临问题

1. mysql数据库磁盘占用持续高位
2. 对于一些计算任务耗时长, 步骤复杂
    1. 美菜日本需要导入gp, 计算后在导回到mysql, 总耗时在3-4小时
    2. 美菜美国在mysql计算, 耗时越1小时
    3. 点评/58等也耗时较久
    4. 同时这些计算也会影响mysql的性能

### 2. 当前推进方案[数据归档的建议](##数据归档的建议)

补充归档程序, 根据项目特点和数据量, 选定冷数据(超过半年的, 数据量较大的原始数据, 已经传输到redshift, 通常没有查询需求的)

1. 备份: mysql >> csv >> aws s3
2. 删除mysql中的冷数据
3. 如果有需要, 从s3恢复冷数据到mysql
4. 缺点:
    1. 直接删除数据后, InnoDB引擎并不能及时释放空间, 而倒表又可能会影响新数据的写入和自增id的管理问题
    2. 如果有整表重传需求, 归档数据恢复耗时费力
    3. 归档数据几乎不可读
5. 备份细节
    1. csv包含id
    2. s3保存gzip压缩后的文件
    3. 按ts来设置目录 /db/table/year/month/day/1.csv
    4. 按大小切割 64M
    5. 最终备份方案替代传输程序, 备份桶代替掉当前传输使用的文件桶

### 3. 考虑优化方向

建议采用百观大数据技术栈调整数据存储方案, 大致如下:

1. mysql存储热数据(三到六个月内), 满足爬虫使用
2. s3存放全部数据

### 4. 迁移aws可行性分析

1. mysql磁盘低占用, 数据写入更加安全
2. s3 to redshift 有更好的解决方案, 可以将数据传输程序和归档程序合二为一, 提高效率
3. s3 + mysql磁盘低占用 带来更低数据存储成本
4. s3数据支持实时查询
5. 对于上述提到的, 计算较复杂的任务(美菜日本/美菜美国/58/点评/popmart), 可以使用aws 大数据计算工具, 会降低计算的耗时和复杂性

## 解决方案实现

2021-04-26 讨论了一下目前aspex的当前情况，以及接下来在数仓上的应用和解决方案, 同步如下。

1. 现有问题
    - 目前的传输程序存在问题
    - 需要有一定计算能力
    - Mysql空间不足
    - Mysql对于数据计算能力不足
2. 解决方案
    - 传输程序：东旭开发了完整的备份、恢复、删除程序，现在正在测试（未来备份程序可替代传输程序）
    - 存储：以后文件都依托s3进行存储和归档，Mysql用来做临时存储和解决字段类型长度截断，去重复数据等基础操作
    - 计算：计算任务将放到数仓中来进行
3. 特殊说明
    - 这些调整和修改不会影响现在生产交付，同时解决了现有的存储和计算问题，并且这些调整也会告知客户

### 1. 同步过程

s3同步mysql数据, s3文件桶中将包含两部分数据, 一部分和mysql一致, 另一部分是mysql归档的数据(暂不替换交付)

1. 数据传输流程: mysql -> csv -> aws s3
2. 数据导出细节(增)
    - csv备份需要包含id在内的完整字段
    - s3保存gzip压缩文件
    - 目录格式
        - 含`ts_short`字段的, 设置目录 /db/table/year/month/day/1.csv
        - 不含`ts_short`字段, 但有类似字段表示数据批次的, `batch_id/update_date...`
        - 完全没有的, 按id区间?
    - ~~按大小切割 64M~~(**按100w行切割后, 基本满足, 暂无需处理**)
    - 备份时间: 备份截止当天(不包含当天)
    - 备份表的范围参考现有传输程序
        1. update=2 全量更新表, 整表备份
        2. update=1 增量传输, 增量备份
        3. update=0 只传输一次, 新表备份, 之后不备份
3. 删
    1. 直接删除mysql中的数据
    2. 将需要删除的s3文件迁移到被删除目录(如果删除数据仅是csv中部分数据, 可以将保留数据查询出来后保存)
4. 改
    1. 对应数据用恢复程序导入mysql
    2. 将需要删除的文件迁移到被删除目录
    3. 在mysql中修改后再导出

### 2. mysql历史数据删除程序

(**删除的前提是备份程序正常运行, 所有数据都已经备份**)

1. 删除范围(**同时满足**):
    1. 增量传输表执行删除操作(update=1)
    2. 限定行数超过1000w的表?
    3. **Hotels中luckin相关的表不能删**, (luckin.shops, luckin.shops_other)
2. 常规删除(表中包含ts_short字段的原始数据)
    1. 按ts_short 定期删除
    2. 保存删除日志, 确保传输校验程序正常运行
3. 对于计算表, 不包含ts_short, 使用替代字段删除(batch_id, update_date)
4. 手动删除(有的表历史空间占用大, 超过100G, delete操作不释放空间)
    1. 手动truncate表
    2. 使用恢复程序恢复近期数据(3-6个月的热数据)

### 3. 恢复程序

按需从s3恢复数据到mysql

### 4. 对于之前自动程序删除的内容(2021-04之前)

- 这部分数据可以从s3获取
- 因为不包含id, 且目录格式和新格式不一致, 需要添加id后按新格式备份
- 这部分数据备份优先级最低

------

## 归档实施记录

### 1. 初步处理

针对容量很大的表(100G级别)处理, 将mysql磁盘占用降到安全范围内(60%-70%)

1. 执行方式参考上述删除程序的手动删除部分
2. 操作表
    - mercari
        - [ ] mercari.app_user
        - [ ] mercari.us_sku
    - 58/zhilian
        - [ ] Jobs.zhilian_job
        - [ ] Jobs.58_job
        - [ ] Jobs.58_job_from_company
        - [ ] Jobs.58_job_info
    - popmart
        - [ ] popmart.chouhe_boxes

### 2. 常规实现
